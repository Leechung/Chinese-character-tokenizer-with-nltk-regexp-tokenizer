# Chinese-charectar-tokenizer-with-nltk-regexp-tokenizer
a nltk tool for tokenizing chinese sentence. the sentence is mixed with english words, numbers. 
